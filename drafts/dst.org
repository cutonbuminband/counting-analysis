#+PROPERTY: header-args:jupyter-python  :session dst :kernel reddit
#+PROPERTY: header-args    :pandoc t :tangle yes
#+TITLE: Daylight Saving Time: On modelling and robustness

In a [[https://cutonbuminband.github.io/counting-analysis/time.html][previous post]] I looked at the daily rhythm of [[http://www.reddit.com/r/counting][r/counting]], at what time of day the subreddit is most active, and how that has changed throughout the years. Zooming in on a small aspect, this post will focus on the effect of daylight saving time on the timing of counts.

Now, DST occurs at different times (if at all) throughout the world, so I've focussed exclusively on DST in the US & Canada, where it starts on the second Sunday in March and ends on the first Sunday of November of each year[fn:1][fn:2].

I have the UTC timestamps for every count, so it's possible to compare our counting activity just before DST comes into force with our counting activity just afterwards, and see whether there's a difference. If counts always follow the same pattern in local time, and all counters observe DST at the same time, then that should show up as a rigid shift in the data. 

* Imports and loading
We'll start off with some code to import the relevant packages and load the data.

#+begin_src jupyter-python
  #| code-fold: true
  #| code-summary: "Code for importing packages and loading data"
  from pathlib import Path
  import pandas as pd
  import sqlite3
  import matplotlib.pyplot as plt
  import numpy as np
  from rcounting import counters, analysis, graph_tools, plots, units
  from IPython.display import Markdown
  import itertools
  import seaborn as sns
  from datetime import datetime, timedelta
  sns.set_theme()

  data_directory = Path("../../data")
  db = sqlite3.connect(data_directory / "counting.sqlite")
#+end_src

* A first model

To see the effect of dst, we can compare the time of day plots for the weeks just before and just after DST is introduced, and see if there are any obvious differences. To maximise the effect of DST, it makes sense to focus only on counts that occurred Monday to Friday, since people's school or working hours should generally be more regular than their weekends.


To start with, we need some code to find when DST started on any given year
#+begin_src jupyter-python
  #| code-fold: true
  #| code-summary: "Finding the start of DST for every year"
  days = ["monday", "tuesday", "wednesday", "thursday", "friday", "saturday", "sunday"]
  def find_nth_weekday(year, month, weekday, n):
      d = datetime(year, month, 1 + 7 * (n - 1))
      offset = (days.index(weekday.lower()) - d.weekday()) % 7
      return d + timedelta(offset) + timedelta(hours=2)

  WEEK = 7 * 24 * units.HOUR
  OFFSET = 5 * units.HOUR
  BIN_WIDTH = 30
  nbins = int(units.DAY / BIN_WIDTH)
  BIN_TO_MINUTE = (BIN_WIDTH / 60)
  x = np.linspace(0, units.DAY, nbins, endpoint=False) + BIN_WIDTH / 2
  dy = 0.07
  years = range(2012, 2024)
  import calendar
  dst_start = {year: calendar.timegm(find_nth_weekday(year, 3, 'sunday', 2).timetuple()) for year in years}
#+end_src

With that out of the way, we'll select the weeks just before the start of DST and the weeks just after the end of DST for every year in r/counting's history.

#+begin_src jupyter-python
  #| code-summary: "Code for getting the raw data into slightly more manageable shape."
  def wrangle(data, week_map=dst_start):
      data = data.reset_index(drop=True)
      data["timestamp"] = data["timestamp"] - OFFSET
      data["date"] = pd.to_datetime(data["timestamp"], unit="s")
      data['time'] = (data['timestamp']) % units.DAY
      data["week"] = (np.floor((data["timestamp"]
                                - pd.to_datetime(data["timestamp"], unit="s").dt.year.map(week_map))
                               / WEEK)
                      .astype(int))
      data["year"] = data["date"].dt.year
      return data

  def generate_kdes(df):
      n_weeks = len(df["week"].unique())
      kdes = (df
              .groupby("week")["time"]
              .apply(lambda x: pd.Series(analysis.fft_kde(
                  x,
                  nbins,
                  kernel="normal_distribution",
                  sigma=0.02)[1] * nbins))
              .reset_index()[["week", "time"]])
      kdes["x"] = np.hstack(n_weeks*[x])
      kdes.columns = ["week", "rate", "time"]
      return kdes

#+end_src

#+begin_src jupyter-python
  query = f"select timestamp, username from comments where timestamp between {{}} and {{}} order by timestamp"

  spring_all = wrangle(
      pd.concat(
          [
              pd.read_sql(query.format(x + OFFSET - 3 * WEEK, x + OFFSET + 3 * WEEK), db)
              for x in dst_start.values()
          ]
      )
  )

  def mask(df):
      return ((df["date"].dt.weekday < 5)
              & (-2 <= df["week"])
              & (df["week"] < 2))

  spring = spring_all[mask(spring_all)].copy()
  spring_kdes = generate_kdes(spring)
  week_map = {-2: "Control without DST",
              -1: "Without DST",
              0: "With DST",
              1: "Control with DST"}
  spring_kdes["week_name"] = spring_kdes["week"].map(week_map)

#+end_src

And we're ready to plot the distribution of counts throughout the day for the week before and the week after the introduction of DST, and see how they differ
#+begin_src jupyter-python
  for week in ["With DST", "Without DST"]:
      df = spring_kdes.query("week_name == @week")
      plt.fill_between(df["time"], df["rate"], alpha=0.8, label=week)
  ax = plt.gca()
  plots.make_time_axis(ax)
  ax.set_ylabel("Counting rate (arbitrary units)")
  ax.set_xlabel("Time of Day (UTC - 5)")
  ax.legend()
#+end_src


The shape of the two plots is similar, and it looks like the plot with DST is generally leading the one without, as would be expected if one was just a rigid shift of the other. But it's certainly not a perfect match, and it's hard to see from the curves just how much the DST curve is leading.

We can try and see what the optimal shift of the DST curve would be to get it to match the curve without DST.
#+begin_src jupyter-python
  def calculate_shifted_overlap(df, week1, week2):
      fixed = df.loc[df["week_name"] == week2, "rate"].to_numpy()
      rotating = df.loc[df["week_name"] == week1, "rate"].to_numpy()
      norm = np.trapz(fixed * rotating, x=x)
      shifts = [np.trapz(fixed * np.roll(rotating, i), x=x) / norm for i in range(len(fixed))]
      optimal_shift = (np.argmax(shifts) + nbins / 2) % nbins - nbins/2
      return shifts, optimal_shift

  shifts, optimal_shift = calculate_shifted_overlap(spring_kdes, "With DST","Without DST")

  plt.plot(shifts)
  plt.xlim(0, len(shifts))
  ax = plt.gca()
  ticks, labels = zip(*[(x * 120, f"{x:02d}:00") for x in range(0, 25, 3)])
  ax.set_xticks(ticks)
  ax.set_xticklabels(labels)
  print(f"The optimal shift is {int(optimal_shift * BIN_TO_MINUTE)} minutes.")

  ax.set_xlabel("Shift (hours)")
  ax.set_ylabel("Similarity score")
  plt.show()
#+end_src

That's a bit less than one hour, but it's still suggestive. Apparently we can use the counting data to determine whether or not DST is currently active.

So, case closed, right?
* Validating the model
Not so fast.

It could be that there's a shift of one hour every week and DST has nothing to do with it! More seriously, there are other changes happening throughout the time period apart from DST; in the spring the days are getting longer, particularly the evenings, and maybe that's what's driving the change. And I haven't at all looked at what happens when the clocks go back.

** Adding more weeks
Let's start by looking at what happens before DST is active. For the preceding analysis to be valid, we'd need the distribution of counts throughout the day to be basically the same for the period just before DST is active and the control period one week before that.
#+begin_src jupyter-python
  for week in ["Without DST", "Control without DST"]:
      df = spring_kdes.query("week_name == @week")
      plt.fill_between(df["time"], df["rate"], alpha=0.8, label=week)
  ax = plt.gca()
  plots.make_time_axis(ax)
  ax.set_ylabel("Counting rate (arbitrary units)")
  ax.set_xlabel("Time of Day (UTC - 5)")
  ax.legend()
#+end_src

Hm. Those two curves might be slightly more aligned than the two with and without DST, but it's not super clear. We can check the optimal shift

#+begin_src jupyter-python
  _, optimal_shift = calculate_shifted_overlap(spring_kdes, "Without DST", "Control without DST")
  print(f"The optimal shift is {int(optimal_shift * BIN_TO_MINUTE)} minutes.")
#+end_src

That's an even bigger shift than the one that happened when DST was introduced! We can plot four the curves for the two weeks before and after DST together and see if there's any obvious pattern.
#+begin_src jupyter-python
  spring_kdes["shifted_rate"] = spring_kdes["rate"] + (spring_kdes["week"] + 2) * dy
  ax = sns.lineplot(spring_kdes, x="time", y="shifted_rate", hue="week_name")
  ax.legend_.set_title("Week")
  plots.make_time_axis(ax)
  ax.legend(loc="upper center", ncol=2)
  ax.set_ylabel("Counting rate (arbitrary units)")
  ax.set_xlabel("Time of Day (UTC - 5)")
  ax.set_ylim(0, 0.34)
#+end_src

If you didn't have the legend, would you be able to tell which two of these curves were with DST and which were without?

** Including the end of DST
We can try and see if including the data for when the clocks go back each year makes any difference
#+begin_src jupyter-python
  dst_end = {year: calendar.timegm(find_nth_weekday(year, 11, 'sunday', 1).timetuple()) for year in years}
  autumn_all = wrangle(pd.concat([pd.read_sql(query.format(x - 3*WEEK + OFFSET, x + 3*WEEK + OFFSET), db)
                                  for x in dst_end.values()]),
                       dst_end)
  autumn = autumn_all[mask(autumn_all)].copy()
  autumn["week"] = -1 - autumn_all["week"]

#+end_src

#+begin_src jupyter-python
  #| label: fig-autumn-kdes
  #| fig-cap: The aggregated activity on r/counting in the two weeks leading up to the end of DST, and the two weeks after it.
  kdes = generate_kdes(pd.concat([spring, autumn]))
  kdes["week_name"] = kdes["week"].map(week_map)
  kdes["shifted_rate"] = kdes["rate"] + (kdes["week"] + 2) * dy
  ax = sns.lineplot(kdes, x="time", y="shifted_rate", hue="week_name")
  ax.legend_.set_title("Week")
  plots.make_time_axis(ax)
  ax.legend(loc="upper center", ncol=2)
  ax.set_ylabel("Counting rate (arbitrary units)")
  ax.set_xlabel("Time of Day (UTC - 5)")
  ax.set_ylim(0, 0.34)
  _, optimal_shift = calculate_shifted_overlap(kdes, "With DST", "Without DST")
  print(f"The optimal shift is {int(optimal_shift * BIN_TO_MINUTE)} minutes.")

#+end_src

As before -- would you be able to tell which of these graphs were with DST and which were without if you didn't have the legend?

** Summing up

The validation of the model has revealed that the activity on r/counting varies enough on a week to week basis that our initial assumptions are incorrect, and we can't just treat the activity as a constant background with a DST signal on top. If we want to see the effect of DST, we're going to have to come up with something more clever.

* More Advanced Models

The analysis of the previous section attempted to describe the activity on r/counting for all years /relative to the DST onset/, and then examined if there was any obvious change as we moved from winter time to summer time (and back again). 

#+begin_src jupyter-python
  spring_all["date"] = pd.to_datetime(spring_all["timestamp"], unit="s")
  x = spring_all.groupby(spring_all["date"].dt.year).apply(lambda x: x.resample("300s", on="date").count())["timestamp"].to_frame()
  x.columns = ["count"]
  x["count"].div(x.groupby(pd.Grouper(level=1, freq='D'))["count"].transform("sum"))
#+end_src


- look at how much each day resembles the previous one and the previous week; plot across DST boundary and see if a change is visible
- Find the most regular counter by the above metric and see if their stats show anything interesting
- Disaggregate the years; apparently we don't have long-term correlations in how we count, so maybe the signal is getting lost there.





* Conclusion

I've tried doing a bunch more stuff to get the dst signal more clearly, like only taking counts from counters I know to be based in the US or Canada, but nothing has worked particularly well. This is all getting rather far away from my field, so I think I'll leave it here. I'm sure that cleverer people than me have come up with a way of getting more signal out of this noise, but it's not something I know about.

If you want to find out whether or not the US currently has DST, then looking at the comments on r/counting is a potentially viable method for doing so. Just googling it would probably be a better approach, though.

Hope you found this interesting!


[fn:1]Apart from Hawaii and Arizona, which are weird
[fn:2]That hasn't always been the DST rule, but it's been the case for as long as r/c has existed
