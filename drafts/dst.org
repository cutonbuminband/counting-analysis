#+PROPERTY: header-args:jupyter-python  :session dst :kernel reddit
#+PROPERTY: header-args    :pandoc t :tangle yes
#+TITLE: Daylight Saving Time: On modelling and robustness

In a [[https://cutonbuminband.github.io/counting-analysis/time.html][previous post]] I looked at the daily rhythm of [[http://www.reddit.com/r/counting][r/counting]], at what time of day the subreddit is most active, and how that has changed throughout the years. Zooming in on a small aspect, this post will focus on the effect of daylight saving time on the timing of counts.

Now, DST occurs at different times (if at all) throughout the world, so I've focussed exclusively on DST in the US & Canada, where it starts on the second Sunday in March and ends on the first Sunday of November of each year^([*])^([+]).

I have the UTC timestamps for every count, so it's possible to compare our counting activity just before DST comes into force with our counting activity just afterwards, and see whether there's a difference. If counts always follow the same pattern in local time, and all counters observe DST at the same time, then that should show up as a rigid shift in the data. 

* Imports and loading
We'll start off with some code to import the relevant packages and load the data.

#+begin_src jupyter-python
#| code-fold: true
#| code-summary: "Code for importing packages and loading data"
from pathlib import Path
import pandas as pd
import sqlite3
import matplotlib.pyplot as plt
import numpy as np
from rcounting import counters, analysis, graph_tools
import seaborn as sns
sns.set_theme()
from IPython.display import Markdown
data_directory = Path("../../data")
import itertools

db = sqlite3.connect(data_directory / "counting.sqlite")
counts = pd.read_sql("select username, submission_id, position from comments where position > 0 order by timestamp", db)
counts["username"] = counts["username"].apply(counters.apply_alias)
counts["position"] = (counts["position"] - 1) % 1000 + 1

#+end_src
* A first model

I've taken all the counts and looked at our activity in the week just before/after dst started/ended every year. To maximise the effect of DST, I've only picked the counts that occurred during the Monday-Friday, since I'd expect people's weekends to be less regular than the weekdays. [Here's](https://i.imgur.com/owaItiu.png) how that plot looks. You can see that the lines with DST generally leads the one without DST, and they have roughly the same shape, particularly in the interval between 12 noon and midnight. This seems to be the fingerprint of the DST change: a rigid shift of about one hour. Using a bit of fiddling I can calculate what the optimal shift is to make the two curves overlap, and get the result 67 minutes.


   #+begin_src jupyter-python
     from datetime import datetime, timedelta

     days = ["monday", "tuesday", "wednesday", "thursday", "friday", "saturday", "sunday"]
     def find_nth_weekday(year, month, weekday, n):
         d = datetime(year, month, 1 + 7 * (n - 1))
         offset = (days.index(weekday.lower()) - d.weekday()) % 7
         return d + timedelta(offset)

     years = range(2012, 2022)
     dst_start = [(find_nth_weekday(year, 3, 'sunday', 2)).timestamp() for year in years]
     dst_end = [(find_nth_weekday(year, 11, 'sunday', 1)).timestamp() for year in years]
     one_hour = 3600
     one_day = 24 * one_hour
     one_week = 7 * one_day
     query = "select timestamp - 21600 as timestamp, username from comments where timestamp between {} and {} order by timestamp"

     spring_control_1 = pd.concat([pd.read_sql(query.format(x - 2 * one_week, x - one_week), db) for x in dst_start])
     spring_no_dst = pd.concat([pd.read_sql(query.format(x - one_week, x), db) for x in dst_start])
     spring_dst = pd.concat([pd.read_sql(query.format(x, x + one_week), db) for x in dst_start])
     spring_control_2 = pd.concat([pd.read_sql(query.format(x + one_week, x + 2 * one_week), db) for x in dst_start])

     autumn_control_2 = pd.concat([pd.read_sql(query.format(x - 2 * one_week, x - one_week), db) for x in dst_end])
     autumn_dst = pd.concat([pd.read_sql(query.format(x - one_week, x), db) for x in dst_end])
     autumn_no_dst = pd.concat([pd.read_sql(query.format(x, x + one_week), db) for x in dst_end])
     autumn_control_1 = pd.concat([pd.read_sql(query.format(x + one_week, x + 2*one_week), db) for x in dst_end])

#+end_src
* Validating the model
So, case closed, right?

Not so fast.

It could be that there's a shift of one hour every week and DST has nothing to do with it! More seriously, there are other changes happening throughout the time period apart from DST; in the spring the days are getting longer, particularly the evenings, and in the autumn it's the opposite. That means that these effects should cancel out slightly in the data. Still, it would be nice to check properly: what I should do is to also look at the periods two weeks before and after the change as controls, since they should have most of the other variation, but **not** the dst. 

If I do that, I get the following two plots of [dst with control](https://i.imgur.com/8lYJNvc.png) and [no dst with control](https://i.imgur.com/xSNUJKp.png). Hm. It's not like they're exactly on top of one another. Or that they're following the same general shape. Checking what shifts would best makes the plots coincide gives values 58 minutes and 92 minutes. Oh. Um.

For the [With dst](https://i.imgur.com/8lYJNvc.png) graph it's apparent that the two curves are qualitatively different, and describing one as a shift of the other is misleading: The green curve has a big peak at midnight which is completely missing from the blue one, as well as a pronounced dip in the afternoon. I can [plot](https://i.imgur.com/7mntAI0.png) how well the curves match as a function of time shift, and it's clear that there's a broad region of Â±1 hour where they sort of line up; picking an arbitrary peak in this plateau doesn't really make sense. Phew, that's half the discrepancy swept under the carpet. 

Looking at the graphs without dst, I'm fairly stumped. They don't match up super well, but it does seem like a shift of about 90 minutes would make them match up significantly better. That's most pronounced between midnight and 4am, which is already odd - that's not when rcounting is most active. Looking at the counters involved in the those two peaks in the green and the blue curve, they're significantly different; only 3 counters are present in the top ten lists for both the blue and the green curve, and most of the 17 counters involved are based outside the US & Canada. "Aha", I hear you cry, "maybe the counters involved are experiencing their own version of dst, just at a different time to the US". Unfortunately, that can't be the explanation: summer time in Europe starts at least two weeks after summer time in the US, so it can't interfere there. It also ends sooner than in the US, so if there was an effect from that, it should show up in the "with dst" plot.


#+begin_src jupyter-python
  def prepare(df):
      df['date'] = pd.to_datetime(df['timestamp'], unit='s')
      df['time_of_day'] = df['timestamp'] % (one_day)
      df['username'] = df['username'].apply(counters.apply_alias)
      return df.loc[df['date'].dt.day_name().apply(lambda x: x in weekdays)].copy()


  with_dst = pd.concat([autumn_dst, spring_dst])
  no_dst = pd.concat([autumn_no_dst, spring_no_dst])
  control_1 = pd.concat([autumn_control_1, spring_control_1])
  control_2 = pd.concat([autumn_control_2, spring_control_2])

  # with_dst = autumn_dst
  # no_dst = autumn_no_dst
  # control_1 = autumn_control_1
  # control_2 = autumn_control_2
  weekdays = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday"]
#+end_src


#+begin_src jupyter-python
  import scipy.signal
  n_bins = (24 * 60)
  x_axis = np.linspace(0, one_day, n_bins + 1, endpoint=True)
  labels = ['Control with dst', 'With DST', 'No DST', 'Control without dst']
  fig, ax = plt.subplots(1)
  signals = []
  for i, df in enumerate([control_2, with_dst, no_dst, control_1]):
      df = prepare(df)
      hist, edges = np.histogram(df['time_of_day'], bins=x_axis)
      signal = hist / np.sum(hist) * n_bins
      signals.append(signal)
      if i not in [2, 3]:
          continue
      ax.plot(edges[:-1], signal, label=labels[i])
  ax.set_xlim(0, 24 * 3600 + 1)
  ax.set_xticks([0 * hour, 3 * hour, 6 * hour, 9 * hour, 12 * hour,
                 15 * hour, 18 * hour, 21 * hour, 24 * hour])
  ax.set_xticklabels(['00:00', '03:00', '06:00', '09:00', '12:00',
                      '15:00', '18:00', '21:00', '00:00'])
  ax.legend()
  ax.set_ylabel('Counting rate (arbitrary units)')
#+end_src


#+begin_src jupyter-python
  af = scipy.fft.fft(signals[1]) / 1440 / np.pi
  bf = scipy.fft.fft(signals[2])
  c = scipy.fft.ifft(af * np.conj(bf))

  print(np.linalg.norm(c - c.real))
  plt.plot(c.real)
  ax = plt.gca()
  ax.set_xticks([0, 3 * 60, 6 * 60, 9 * 60, 12 * 60,
                 15 * 60, 18 * 60, 21 * 60, 24 * 60])
  ax.set_xticklabels(['0', '3', '6', '9', '12',
                      '-9', '-6', '-3', '0'])
  ax.set_xlabel('Time shift (hours)')
  ax.set_ylabel('Overlap')
  val = c.real.argmax()
  print(min(val, 1440 - val))
#+end_src


* Conclusion

I've tried doing a bunch more stuff to get the dst signal more clearly, like only taking counts from counters I know to be based in the US or Canada, but nothing has worked particularly well. This is all getting rather far away from my field, so I think I'll leave it here. I'm sure that cleverer people than me have come up with a way of getting more signal out of this noise, but it's not something I know about.

If you want to find out whether or not the US currently has DST, then looking at the comments on r/counting is a potentially viable method for doing so. Just googling it would probably be a better approach, though.

Hope you found this interesting!


^([*]) Apart from Hawaii and Arizona, which are weird
^([+]) That hasn't always been the DST rule, but it's been the case for as long as r/c has existed
