[
  {
    "objectID": "time.html",
    "href": "time.html",
    "title": "Tick Tock: looking at counting activity over time",
    "section": "",
    "text": "Reddit helpfully provides us with time stamps for each comment, so we know exactly when each count on the counting chain was made. This information can be used for a wealth of different things, but in this post I’ll focus on what the data can tell us about the daily rhythm of r/counting; about what time of day the subreddit is most active, and about how that has changed throughout the years.\nWe’ll start off with some code to import the relevant packages and load the data\n\n\nCode for importing packages and loading data\nfrom pathlib import Path\nimport pandas as pd\nimport sqlite3\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy\nfrom rcounting import counters, analysis, graph_tools, units\nimport seaborn as sns\nsns.set_theme()\nfrom IPython.display import Markdown\ndata_directory = Path(\"../data\")\nimport networkx as nx\nimport itertools\n\ndb = sqlite3.connect(data_directory / \"counting.sqlite\")\ncounts = pd.read_sql(\"select username, timestamp from comments order by timestamp\", db)\ncounts[\"username\"] = counts[\"username\"].apply(counters.apply_alias)\n\n\nThe first thing we’ll look at is how the average rate of counts varies throughout the day. That’s shown on Figure 1.\n\n\nCode\noffset = 5 * units.HOUR\nfig, ax = plt.subplots(1)\nnbins = int(units.DAY / 30)\ncounts['time'] = (counts['timestamp'] - offset) % units.DAY\ndt = counts['timestamp'].iat[-1] - counts['timestamp'].iat[0]\navg_counts_per_day = len(counts) / dt * units.DAY\nx, kde = analysis.fft_kde(counts['time'], nbins, kernel=\"normal_distribution\", sigma=0.01)\nkde = kde * avg_counts_per_day * units.MINUTE\nax.fill_between(x, kde, alpha=0.8)\nax.axhline(len(counts) / dt * units.MINUTE, color=\"0.7\", linestyle=\"--\")\nticks, labels = zip(*[(x * units.HOUR, f\"{x:02d}:00\") for x in range(0, 25, 3)])\ndef prettify(ax):\n    ax.set_xlim(0, units.DAY + 1)\n    ax.set_xticks(ticks)\n    ax.set_xticklabels(labels)\n    ax.set_ylim(bottom=0)\n    ax.set_xlabel(\"Time of day (UTC - 5)\")\nax.set_ylabel(\"Average rate [counts/minute]\")\nprettify(ax)\n\n\n\n\n\nFigure 1: The average rate of counts at different times of day. The horizontal line shows the global average.\n\n\n\n\nYou can see that the counting rate varies quite a bit - the most popular time (early afternoon EST) has an average counting rate that’s almost four times higher than the least popular time (late night/early morning EST). It’s also nice to have a feeling for what a “normal” rate of counting has been, and it turns that it’s on the order of one count per minute.\nIf the rate of counting were perfectly uniform, the chart would be perfectly flat. If every count was always made at precisely 12:00 there would be an infinitely tall spike right at the middle of the graph, and the rate would be zero at all other times. It would be nice to be able to quantify just how far away the distribution is from uniform. Some statisticians have come up with the Coefficient of Variation to do precisely that1; it says that the variation of a sample of values can be expressed as the ratio of the standard deviation to the mean. If we do this for our time of day data, we obtain1 I spent 5 minutes playing with \\(L^2\\) norms before I realised I was reinventing the wheel\n\n\nCode\nprint(f\"{np.sqrt(kde.var()) / kde.mean() * 100:.1f}%.\")\n\n\n33.2%.\n\n\nIt’s of course also possible to calculate this variation for individual counters, and not just for all counters together. The counters in the top 30 with most and least variation are shown on Table 1.\n\n\nCode\ndef get_tod_variation(group):\n    x, kde = analysis.fft_kde(group['time'], nbins, kernel=\"normal_distribution\", sigma=0.01)\n    return np.sqrt(kde.var()) / kde.mean()\n\ntop_counters = counts.groupby(\"username\").size().sort_values(ascending=False).index\ntop_counters = [x for x in top_counters if not counters.is_banned_counter(x)][:30]\ntop_30 = counts.query(\"username in @top_counters\")\ntod_variations = top_30.groupby(\"username\").apply(get_tod_variation).sort_values()\nhead = pd.concat([tod_variations.head(3), tod_variations.tail(3)]) * 100\ncombined = head.to_frame(\"variation\").join(pd.DataFrame(top_counters).reset_index().set_index(0))\nMarkdown(combined.to_markdown(headers=[\"**Counter**\", \"**Time of day variation**\", \"**HOC position**\"], floatfmt=\".0f\"))\n\n\n\n\nTable 1: The most and least regular counters\n\n\nCounter\nTime of day variation\nHOC position\n\n\n\n\nTheNitromeFan\n41\n7\n\n\nTehVulpez\n51\n21\n\n\natomicimploder\n57\n8\n\n\ncupofmilo\n109\n25\n\n\nLeMinerWithCheese\n121\n23\n\n\nTrial-Name\n130\n11\n\n\n\n\n\n\nAs an aside, you should notice that even the most regular counter has a variation that is higher than the overall variation. Intuitively that makes sense - it’s harder for one person to evenly cover all 24 hours of the day than it is for all counters together. We can focus on the single least and most regular counters and look at how their counting rates have varied throughout the day. Here’s a plot of that:\n\n\nCode\nfig, ax = plt.subplots()\nfor index in [0, -1]:\n    username = tod_variations.index[index]\n    x, kde = analysis.fft_kde(counts.query(\"username == @username\")['time'], nbins, kernel=\"normal_distribution\", sigma=0.01)\n    ax.plot(x, kde / kde.mean(), label=username)\nax.legend()\nax.set_ylabel(\"Normalized counting rate\")\nprettify(ax)\n\n\n\n\n\nIt’s not too surprising, but those distributions look very different!\n\nThe evolution of the counting distribution\nThe previous section provided one view into the activity on r/counting and how it’s qualitatively different for different people, and at different times of day. One potential issue with that analysis is that it’s a static view of the data, and thus ignores any changes there might have been over time. Different people have been active at different periods of time in r/counting history, and they’ve probably tended to count at different times of day. But the foregoing completely ignores that.\nTo see if (and how) the distributions of counts have changed over time it would in principle be possible to make a plot like Figure 1 for each year or month of activity on r/counting, and then compare them. Alternatively, we could add a third axis to the plot and make a single three-dimensional plot, which might show what we want. I always find those really difficult to read, so that doesn’t seem too appealing. On the other hand, if it were possible to show a single distribution in just one dimension instead of two, then we could put lots of those next to each other and build up a two-dimensional plot. One way of accomplishing this is by using colour and shading.\nWhat I’ll do is split the timestamp of each count into a day componentand a time of day component, and then plot the day on the x axis and the time of day on the y axis. This is done on figure Figure 2 in the form of a hexbin plot: the darker the colour of each hexagon, the more counts were made on that date and at that time of day.\n\n\nCode\nsns.set_theme(style=\"ticks\")\nimport matplotlib.dates as mdates\ncounts['date'] = pd.to_datetime(counts['timestamp'], unit='s')\ncounts['numerical_date'] = mdates.date2num(counts['date'])\ncounts['flipped_time'] = units.DAY - counts['time']\ngrid = sns.jointplot(x='numerical_date',\n                     y='flipped_time',\n                     kind=\"hex\",\n                     data=counts,)\ngrid.set_axis_labels()\nax = grid.ax_joint\ndef prettify_timeseries(ax):\n    ax.xaxis_date()\n    locator = mdates.AutoDateLocator(minticks=3, maxticks=7)\n    formatter = mdates.ConciseDateFormatter(locator)\n    ax.xaxis.set_major_locator(locator)\n    ax.xaxis.set_major_formatter(formatter)\n    ax.set_xlim([counts['numerical_date'].min(), counts['numerical_date'].max()])\n    ax.set_yticks(units.DAY - np.array(ticks))\n    ax.set_yticklabels(labels)\n    ax.set_ylim([0, units.DAY])\n    ax.set_xlabel(\"Date\")\n    ax.set_ylabel(\"Time of Day (UTC - 5)\")\nprettify_timeseries(ax)\n\n\n\n\n\nFigure 2: An illustration of every count made on the main thread; the darker the colour of any particular hexagon, the more counts were made in the area it covers.\n\n\n\n\nThe plot is a bit difficult to follow, and that’s kind of the point - it’s trying to cram a lot of data into not very many pixels. On the right, you can see the global time of day distribution; tht’s basically the same as what’s plotted in fig-kde, but stretched out a bit. On top, you can see the overall counting rate which is very spiky. You can see how the rate was basically zero in 2012; and and then was higher but still low until late 2015 where it shot up. In 2016 and 2017 the rate was high, but gradually falling, reaching a minimum in late 2017, followed by an increase to very high levels in late 2019. Since then, the rate has generally been much lower, but with two important peaks.\nTurning to the joint plot, it tries to show both of these things at the same time. It’s illustrative perhaps to compare the counting activity in early 2016 with that in early 2020. The top histogram shows that the counting rates at these two times was roughly similar, but the main chart reveals that how these counts took place was very different. In 2016, the counting activity was spread out throughout the day, with a small dip between 04:00 and 07:00. In 2020, there was a pronounced peak of activity between 13:00 and 18:00, a smaller peak centered at 04:00 and much less activity throughout the rest of the day.\nWe can also look at the peak in early 2021. This one shows a lot of activity from 10:00 to 17:00, with a small dip at around 12:00. Perhaps one of the people involved had to go for lunch.\n\nSummary statistics and the circular mean\nCreating and looking at the hexbin plot let us confirm the fact that just showing the average distribution hides a lot of structure. In particular, we can see that\n\nThe counting rate varies a lot over time\nThe time of day distribution also changes a lot\n\nQuantitatively, it’s difficult to say more than that based on the figure. There’s just too much going on, and it would be nice if we could simplifiy it.\nWhat we’d really need is some kind of summary statistic for a time of day distribution, because then we can easily plot how that summary statistic varies over time. An obvious first choice could be the mean of the distribution, to represent what time of day the average count takes place.\nUnfortunately, it’s not so simple. The time of day data is circular, and the standard mean is badly suited for this use case. To illustrate, we can consider what the average time is of two events, one occurring at 23:59 and the other at 00:001. If we just use the linear mean, we arrive at 12:00, but intuitively the answer should be 00:00.\nWhat we can use instead is the circular mean. You can imagine this as pretending we have a 24h analog clock, and each event is an arrow points to its correct time. The arrow tail is at (0, 0), and the arrow head is at position (x, y), corresponding to whatever time it is. What we want to do is to find the average angle of all the arrows, and to do that we average all the x positions separately, and all the y positions separately, and create a new arrow that points to (average x, average y). The angle we want is then the angle of this arrow.\nWe can do that for the overall counting distribution to obtain\n\n\nCode\nmean = scipy.stats.circmean(counts['time'], high=units.DAY)\nhour, rem = divmod(mean, 3600)\nminute, second = divmod(rem, 60)\nprint(f\"The mean of the overall distribution is {int(hour):02d}:{int(minute):02d}\")\n\n\nThe mean of the overall distribution is 16:33\n\n\nThat seems reasonable - it’s inside the broad afternoon peak of activity, but slightly to the right, since there’s more activity in the evening than in the early morning.\nWith the summary statistic in hand, we can plot how the mean time of day of counts has varied over time\n\n\nCode\ncounts.set_index('date', inplace=True)\ncounts['x'] = np.cos(counts['time'] / units.DAY * 2 * np.pi)\ncounts['y'] = np.sin(counts['time'] / units.DAY * 2 * np.pi)\nrolling = counts[['x', 'y', 'numerical_date']].rolling('28d').mean()\nrolling['time_of_day'] = (np.arctan2(rolling['y'], rolling['x']) * units.DAY / 2 / np.pi) % units.DAY\nrolling = rolling.resample('7d').mean()\n\nsns.set_theme()\nfig, ax = plt.subplots()\nrolling[\"seconds_to_midnight\"] = units.DAY - rolling[\"time_of_day\"]\nax = sns.regplot(x=\"numerical_date\", y=\"seconds_to_midnight\", data=rolling)\nprettify_timeseries(ax)\n\n\n\n\n\nThis analysis shows that from the start of r/counting until 2023, the average time of day of each count has drifted by about six hours. More precisely, we can say that\n\n\nCode\n  Markdown(f\"The average time has shifted by {np.polyfit(rolling['numerical_date'], rolling['time_of_day'], 1)[0]:.1f} seconds per day.\")\n\n\nThe average time has shifted by -6.3 seconds per day.\n\n\nThis shift is not something that was at all apparent from Figure 2, which shows the value of the summary statistic for revealing trends in the data."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is my website for publishing interesting bits and pieces of r/counting data and graphs in a central place. The code builds on the rcounting tools that I develop here"
  },
  {
    "objectID": "examples.html",
    "href": "examples.html",
    "title": "Examples",
    "section": "",
    "text": "Imports and initialization\nWe start with some imports, which aren’t particularly interesting, so they’ve been folded.\n\n\nCode for importing packages\nimport pandas as pd\nfrom rcounting import side_threads, thread_navigation as tn\n\n\n\n\nValidating side threads\nThe rcounting tools have various pieces of functionality to validate the side threads it knows about, both in terms of whether the counts follow the expected format, and whether the thread obeys any special rules that might apply. Here’s an example of what that looks like in a python script.\n\n\nCode\n# Pick a comment early in a chain\ncomments = pd.DataFrame(tn.fetch_comments(\"gja0ehe\"))\nside_thread = side_threads.get_side_thread('slowestest')\nprint(\"The thread is valid!\" if side_thread.is_valid_thread(comments) else \"The thread is invalid\")\n\n\nThe thread is valid!\n\n\nThe thread is valid - excellent! There’s also a script that you can run from the command line to validate the most common threads. Try typing rcounting validate -h in a terminal to see how to use it.\n\n\nNetwork analysis\nThe rcounting tools also have functionality to do some network analysis. The following snippet will generate the (comment, replying to, weight) graph for the top 250 counters. The heavy lifting is done by the response graph [[file:../rcounting/analysis.py::def response_graph(df, n=250, username_column=“username”):][response_graph]] function in analysis.py.\n\n\nCode\nfrom rcounting import analysis, counters\nimport sqlite3\nfrom pathlib import Path\ndata_directory = Path(\"../data\")\ndb = sqlite3.connect(data_directory / \"counting.sqlite\")\ncounts = pd.read_sql(\"select comments.username \"\n                       \"from comments join submissions \"\n                       \"on comments.submission_id = submissions.submission_id \"\n                       \"where comments.position > 0 \"\n                       \"order by submissions.timestamp, comments.position\", db)\ncounts[\"username\"] = counts[\"username\"].apply(counters.apply_alias)\nn = 250\ngraph = analysis.response_graph(counts, n, username_column=\"username\")\ngraph.sort_values(ascending=False, by=\"Weight\").head()\n\n\n\n\n\n\n  \n    \n      \n      Source\n      Target\n      Weight\n    \n  \n  \n    \n      14960\n      thephilsblogbar2\n      GarlicoinAccount\n      98844\n    \n    \n      2869\n      GarlicoinAccount\n      thephilsblogbar2\n      98821\n    \n    \n      1657\n      Countletics\n      nonsensy\n      92922\n    \n    \n      12832\n      nonsensy\n      Countletics\n      92922\n    \n    \n      873\n      Antichess\n      Countletics\n      73007"
  },
  {
    "objectID": "separators.html",
    "href": "separators.html",
    "title": "The use of separators",
    "section": "",
    "text": "We have access to the body of each comment, so it’s possible to do some of analysis on those. One interesting thing could be to look at whether a given count is comma separated, space separated or uses no separator at all. And a natural question to ask is how the distribution between those three types has changed over time\nSpecifically, we’ll define the three types of count as:\n\nComma separated counts look like [digit]*{1-3}(,[digit]*3)*\nSpace separated counts are the same, with the comma replaced by a space\nNo separated counts are defined as one of\n\nCounts with only one digit\nCounts with no separators between their first and last digit, with separators defined fairly broadly.\n\n\n\n\nCode for importing packages and loading data\nfrom pathlib import Path\nimport pandas as pd\nimport re\nimport sqlite3\nimport matplotlib.pyplot as plt\n\nfrom rcounting import parsing\nimport seaborn as sns\nsns.set_theme()\nfrom IPython.display import Markdown\ndata_directory = Path(\"../data\")\ndb = sqlite3.connect(data_directory / \"counting.sqlite\")\n\ncounts = pd.read_sql(\"select comments.body, comments.timestamp from comments join submissions \"\n                       \"on comments.submission_id = submissions.submission_id where comments.position > 0 \"\n                       \"order by submissions.timestamp, comments.position\", db)\ncounts['date'] = pd.to_datetime(counts['timestamp'], unit='s')\ncounts.drop('timestamp', inplace=True, axis=1)\n\n\nWe started by making the necessary imports and loading all the data; with that out of the way we can implement the rules defined above\n\n\nCode\ndata = counts.set_index('date')\n\ndata['body'] = data['body'].apply(parsing.strip_markdown_links)\ncomma_regex = re.compile(r'\\d{1,3}(?:,\\d{3})+')\ndata['is_comma_separated'] = data['body'].apply(lambda x: bool(re.search(comma_regex, x)))\nspace_regex = re.compile(r'\\d{1,3}(?: \\d{3})+')\ndata['is_space_separated'] = data['body'].apply(lambda x: bool(re.search(space_regex, x)))\ndef no_separators(body):\n    body = body.split('\\n')[0]\n    separators = re.escape(\"' , .*/\")\n    regex = (rf\"(?:^[^\\d]*\\d[^\\d]*$)|\"\n             rf\"(?:^[^\\d]*\\d[^{separators}]*\\d[^\\d]*$)\")\n    regex = re.compile(regex)\n    result = re.search(regex, body)\n    return bool(result)\n\ndata['no_separators'] = data['body'].apply(no_separators)\ndata.sort_index(inplace=True)\n\n\nOnce we have the data, we can get a 14-day rolling average, and resample the points to nice 6h intervals. The resampling makes plotting with pandas look nicer, since it can more easily deal with the x-axis.\n\n\nCode\nresampled = (data[['is_comma_separated', 'is_space_separated', 'no_separators']].rolling('14d').mean().resample('6h').mean() * 100)\nfig, ax = plt.subplots(1)\nresampled.plot(ax=ax, ylabel='Percentage of counts', lw=2)\nh, l = ax.get_legend_handles_labels()\nax.legend(h[:3],[\"commas\", \"spaces\", \"no separator\"])\nax.set_ylim([0, 100])\nax.set_xlabel('')\nplt.show()\n\n\n\n\n\nFigure 1: The separators used on r/counting over time\n\n\n\n\nThe result is shown on figure Figure 1\nNotice you can clearly see when the count crossed 100k: that’s when the ‘no separators’ line quickly drops from being the majority to being a clear minority of counts. That was followed by the era of commas, when the default format was just to use commas as separators. Over the last years, commas have significantly declined, and have now been overtaken by spaces as the most popular separator, although there’s a lot of variation depending on who exactly is active. No separators has bouts of activity, but is generally below the other two options. Pretty neat!"
  },
  {
    "objectID": "runs.html",
    "href": "runs.html",
    "title": "Longest runs",
    "section": "",
    "text": "Most counts on r/counting are made by two counters collaborating; the signature of this is that the n^th count and the (n + 2)^th count almost always have the same author. Usually we only consider such collaborative counting a run when the two counters reply to each other at a fairly rapid clip, but I’ve ignored that here\nFirstly, I’ve looked at the longest runs by total time, which I’ve defined as the longest periods of time when only two people counted in main. Unfortunately, that doesn’t give anything very interesting: these are all from early in the subreddit history, where hours would frequently pass between replies, and the runs I’ve found are generally less than ten counts long. An example is from the 24k counting thread, where just over 23 hours passed between two counts here here1. There was only one exception to this trend in the 2M era. Apparently we had a bit of a problem with spammers & farmers back then, and a really long chain of counts was deleted, and the count was continued from a valid point some hours later. The whole thing caused a bit of confusion.1 Plus that was a late chain which somehow became official. I guess we were less strict back then. \n\n\nCode\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nimport re\nimport sqlite3\nimport matplotlib.pyplot as plt\n\nfrom rcounting import side_threads, counters, analysis, thread_navigation as tn, parsing, units\nfrom rcounting.reddit_interface import reddit\nimport seaborn as sns\nsns.set_theme()\nfrom IPython.display import Markdown\ndata_directory = Path(\"../data/\")\ndb = sqlite3.connect(data_directory / \"counting.sqlite\")\ndf = pd.read_sql(\"select counters.canonical_username as username, timestamp, comment_id from comments join counters on comments.username=counters.username where comments.position > 0 order by timestamp\", db)\n\n\nLooking at the longest runs by total number of counts in the run is more interesting. so let’s do that. We take all our ordered counts and shift them by two; if the two authors are different, that means one streak has ended and a new one started. Taking the cumulative sum of all these changes means that each run is assigned the same number; exactly what we want. Table 1 shows the top ten runs in r/counting history, as well as their total length.2:2 I haven’t checked through all of them, but it’s likely all the lengths are off by one. That’s because I’ve forced every comment to be part of only one run, but the first comment in each run should simultaneously be the last comment in the previous run.\n\n\nCode\ncolumn = df['username']\nis_different_group = (column != column.shift(2))\ndf['group'] = is_different_group.cumsum()\ngroups = df.groupby('group')\nindices = (-groups.size().loc[groups.size() > 1]).sort_values(kind='mergesort').index\nold = groups.first().loc[indices]\nnew = groups.last().loc[indices]\nnew['username'] = groups.nth(1).loc[indices]['username']\nold['length'] = groups.size().loc[indices]\ncombined = old.join(new, rsuffix='2', lsuffix='1')\ncombined['dt'] = (combined['timestamp2'] - combined['timestamp1']) / units.HOUR\ncombined.drop(['timestamp1', 'timestamp2'], axis=1, inplace=True)\n\ndef link(comment):\n    body, submission = pd.read_sql(f\"select body, comment_id from comments where comment_id == '{comment}' order by timestamp desc limit 1\", db).iloc[0]\n    return f\"[{parsing.find_count_in_text(body):,}](/comments/{submission}/_/{comment})\"\n\nfinal = combined.head(10).reset_index(drop=True).copy()\n\nfinal[\"old_link\"] = final[\"comment_id1\"].apply(link)\nfinal[\"new_link\"] = final[\"comment_id2\"].apply(link)\nfinal.index += 1\ndef format_time(timedelta):\n    hours, rem = divmod(timedelta.total_seconds(), 3600)\n    minutes, seconds = divmod(rem, 60)\n    return f\"{int(hours):0>2}:{int(minutes):0>2}\"\nfinal['dt'] = pd.to_timedelta(final['dt'], unit='h').round('s').apply(format_time)\nMarkdown(final[['username1', 'username2', 'old_link', 'new_link', 'length', 'dt']].to_markdown(headers=['**Rank**', '**1st counter**', '**2nd counter**', '**Start**', '**End**', '**Length**', '**Duration**']))\n\n\n\n\nTable 1: The 10 longest runs in r/counting history\n\n\nRank\n1st counter\n2nd counter\nStart\nEnd\nLength\nDuration\n\n\n\n\n1\ndavidjl123\nCountletics\n3,037,002\n3,044,030\n7029\n02:44\n\n\n2\ndavidjl123\nCountletics\n3,190,001\n3,195,027\n5027\n02:11\n\n\n3\nCountletics\ndavidjl123\n3,101,028\n3,105,791\n4764\n01:54\n\n\n4\nCountletics\ndavidjl123\n3,072,012\n3,076,715\n4704\n01:56\n\n\n5\nCountletics\ndavidjl123\n3,201,005\n3,205,000\n3996\n01:41\n\n\n6\nCountletics\ndavidjl123\n3,090,222\n3,094,002\n3781\n01:45\n\n\n7\nCountletics\ndavidjl123\n3,064,318\n3,068,003\n3686\n01:37\n\n\n8\nCountletics\nLeMinerWithCheese\n4,569,377\n4,572,402\n3026\n02:43\n\n\n9\nAntichess\nCountletics\n4,218,058\n4,221,003\n2946\n01:31\n\n\n10\ndavidjl123\nGarlicoinAccount\n4,028,324\n4,031,002\n2679\n02:22\n\n\n\n\n\n\nThe first seven runs are by u/davidjl123 and u/Countletics in the early 3Ms, and all of the top ten involve either david or countletics. The first one which doesn’t either of them is number 17 between nonsensy and colby6666, starting at 3,456,003 and continuing for 2000 counts."
  },
  {
    "objectID": "counting_counters.html",
    "href": "counting_counters.html",
    "title": "Counting counters",
    "section": "",
    "text": "I’ve previously described r/counting as a collaborative incremental game, and that for me sums up the essence of counting fairly well. A natural question to ask about the game is how many people have played over the years\nWe’ll start of by importing the relevant packages and loading some data. Since we’re only interested in the counters in each thread, we only load those two columns from the database.\n\n\nCode for importing packages and loading data\nfrom pathlib import Path\nimport pandas as pd\nimport re\nimport sqlite3\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom rcounting import parsing\nimport seaborn as sns\nsns.set_theme()\nfrom IPython.display import Markdown\ndata_directory = Path(\"../data\")\ndb = sqlite3.connect(data_directory / \"counting.sqlite\")\n\ncounts = pd.read_sql(\"select counters.canonical_username as username, submission_id from comments \"\n             \" join counters on comments.username=counters.username \"\n             \"where comments.position > 0 and submission_id != 'uuikz' order by timestamp\", db)\nsubmissions = pd.read_sql(\"select * from submissions\", db)\ndef format_title(row):\n    return f\"[{row.title}](http://www.reddit.com/r/counting/comments/{row.submission_id})\"\nsubmissions[\"link\"] = submissions.apply(format_title, axis=1)\n\n\nNow finding the total number of counters is easy\n\n\nCode\ncounts[\"username\"].nunique()\n\n\n15457\n\n\nThat’s more than I was expecting!\n\nThe number of counters in each thread\nThe counts in r/counting are split into threads of 1000 counts each, and in principle it should be possible to have a thread with 1000 different counters participating. That’s never happened, especially since most counts are made as part of a series of replies between just two users. Still, it might be interesting to see which threads had the most counters taking part:\n\n\nCode\nlevels = counts.groupby(['submission_id', 'username'], sort=False).size()\ntop = levels.groupby(level=0, sort=False).size().sort_values(ascending=False).head()\ntop_submissions =  submissions.query(\"submission_id in @top.index\").copy()\ncombined = pd.concat([top, top_submissions.set_index(\"submission_id\")], axis=1)\nMarkdown(combined[[\"link\", 0]].to_markdown(headers=[\"**Thread**\", \"**Number of counters**\"], index=False))\n\n\n\n\n\nThread\nNumber of counters\n\n\n\n\n100k Counting thread. We are now in the land of six digits.\n189\n\n\n1,103k Counting Thread\n172\n\n\n250K Counting Thread\n148\n\n\n336K Counting Thread\n146\n\n\n389k Counting Thread\n144\n\n\n\n\n\nSome of these threads really had a lot of participants!\nOn the oppositve end of the scale, we can look at the threads with fewest participants. Since you’re not allowed to reply to yourself, at least two people have to take part in each thread. We can easily see how many times that’s happened:\n\n\nCode\nperfect = levels.groupby(level=0, sort=False).size() == 2\nperfect = perfect.loc[perfect].index\nlen(perfect)\n\n\n142\n\n\nSo not a huge amount of times, but it’s happened. The last five threads with only two counters are\n\n\nCode\nperfect_500s = submissions.query(\"submission_id in @perfect\").copy().tail().iloc[::-1]\ndef find_counters(submission_id):\n    return pd.Series(levels.loc[submission_id].index)\nperfect_500s[[\"first_counter\", \"second_counter\"]] = perfect_500s[\"submission_id\"].apply(find_counters)\nMarkdown(perfect_500s[[\"link\", \"first_counter\", \"second_counter\"]].to_markdown(headers=[\"**Thread**\", \"**First Counter**\", \"**Second Counter**\"], index=False))\n\n\n\n\n\nThread\nFirst Counter\nSecond Counter\n\n\n\n\n4915k Counting Thread\nthephilsblogbar2\nClockButTakeOutTheL\n\n\n4762K Counting Thread\nCountletics\nCutOnBumInBandHere9\n\n\n4755k Counting Thread\nCountletics\nCutOnBumInBandHere9\n\n\n4730K Counting Thread\ncolby6666\nthephilsblogbar2\n\n\n4576k Counting Thread\nCountletics\nLeMinerWithCheese\n\n\n\n\n\nWe can plot the distribution of the number of counters in each thread; this is shown on figure Figure 1.\n\n\nCode\nimport numpy as np\n\ncounters = levels.groupby(level=0, sort=False).size()\nax = sns.histplot(counters[counters <= 100])\nax.set_xlim(left=2)\nax.set_xlabel(\"Number of counters\")\nplt.show()\n\n\n\n\n\nFigure 1: The distribution of the number of counters participating in a thread\n\n\n\n\n\n\nEffective number of counters per thread\nThe total number of counters that participate in a thread is an inherently noisy quantity. One person making a single count can change the total even if they make no other counts in the thread. A better way is to look at the effective number of counters taking part in a thread. The effective number takes into account how skewed the distribution of participants is. If 10 people count 100 times each in a thread, then both the actual and the effective number of counters is 10. If instead two people count 496 times each, and 8 people count once each, then the effective number of counters is 2.02, because two people made basically all the counts.\nWe can find the submission with the highest number of effective counters.\n\n\nCode\nfrom rcounting.analysis import effective_number_of_counters\neffective_counters = levels.groupby(level=0, sort=False).apply(effective_number_of_counters)\nsubmission_id = effective_counters.idxmax()\ns = (f\"The thread with the highest number of effective counters is \"\n     f\"{submissions.query('submission_id == @submission_id')['link'].iat[0]}, \"\n     f\"with {effective_counters.loc[submission_id]:.1f} counters.\")\nMarkdown(s)\n\n\nThe thread with the highest number of effective counters is 336K Counting Thread, with 28.2 counters.\n\n\nWe can also compare the total and the effective number of counters\n\n\nCode\ntotal_counters = levels.groupby(level=0, sort=False).size()\nmerged = (pd.concat([effective_counters, total_counters], axis=1))\nmerged.columns = ['Effective counters', 'Actual counters']\n\n\n\n\nCode\ntable = merged.describe().transpose()[[\"mean\", \"50%\", \"max\"]]\nMarkdown(table.to_markdown(floatfmt=\".1f\", headers=[\"**Mean**\", \"**Median**\", \"**Maximum**\"]))\n\n\n\n\n\n\nMean\nMedian\nMaximum\n\n\n\n\nEffective counters\n4.6\n3.6\n28.2\n\n\nActual counters\n20.9\n18.0\n189.0\n\n\n\n\n\nWe can see that both the total and effective number of counters have a median that is lower than the mean, indicating that the distributions have long tails to the right. We can plot these, which is done on figure Figure 2. You can clearly see how much more spread out the actual number of counters is compared with the effective number. The effective number is really sharply peaked at 2, with 25% of the counts lying in the range 2-2.4.\n\n\nCode\nlimits = [2, 50]\nax = merged.plot.kde(ind=np.linspace(*limits))\nax.set_xlim(*limits)\nax.set_ylim(bottom=0)\nplt.show()\n\n\n\n\n\nFigure 2: The distributions of the number of effective and actual counters in each thread\n\n\n\n\nWe can also plot how the effective and actual number of counters have evolved throughout r/counting history; this is shown on figure Figure 3. The actual and effective number of counters track each other quite closely across threads. It seems there’s been a gradual decline in the number of counters participating in each thread, but with spikes of activity. It looks like there’s a sustained uptick right now; let’s hope we keep it up! One thing I was expecting to see was clear spikes at 100k threads, since running isn’t allowed on those. And those spikes just aren’t apparent in the data.\n\n\nCode\nbar = merged.reset_index(drop=True)\nbar.set_index((bar.index + 15)/1000, inplace=True)\nax = bar.rolling(10).mean().plot(secondary_y=['Effective counters'], alpha=0.7)\nax.set_xlim(left=0)\nax.set_xlabel(\"Count [millions]\")\nplt.show()\n\n\n\n\n\nFigure 3: How the number of effective and actual counters has changed through r/counting history, a 10-thread rolling average\n\n\n\n\nWe can also plot the effective number of counters as a function of the actual number of counters. You can see generally, the more actual counters there are in a thread, there more effective counters there will be, but the relationship is fairly noisy.\n\n\nCode\nfit = np.polyfit(merged['Actual counters'], merged['Effective counters'], 1, full=True)\nax = sns.regplot(x='Actual counters', y='Effective counters', data=merged,\n                 line_kws={\"color\": \"k\", \"linestyle\": \"--\"})\nx = np.array([0, 100])\nax.set_xlim(0, 100)\nax.set_ylim(bottom=2)\nplt.title('Actual vs effective number of counters')\nplt.show()"
  },
  {
    "objectID": "network.html",
    "href": "network.html",
    "title": "The r/counting network",
    "section": "",
    "text": "One of the interesting things we can look at using the counting data is the relationships between different counters. For example, and as an introduction, we can ask which counters have replied to each other most often\nTable 1 shows the 10 pairs of counters who have replied directly to each other most often. Evidently it’s more likely that someone will appear in the table if they’ve made a lot of counts, but it’s still interesting to see that the top spot isn’t held by the top two counters.\nWe can also see which counters have counted with the most other people."
  },
  {
    "objectID": "network.html#the-core-of-the-rcounting-graph",
    "href": "network.html#the-core-of-the-rcounting-graph",
    "title": "The r/counting network",
    "section": "The core of the r/counting graph",
    "text": "The core of the r/counting graph\nThe counting community has evolved over time, with new people dropping in, and older counters fading away (and sometimes staging remarkable comebacks).\nIn the counting graph, one person is connected to another if they’ve ever replied to each another. The degree of a person is a count of how many connections they have. There’s a really neat approach to finding the most connected group of people in the graph that goes as follows:\n\nDefine the connectivity score of the graph as the degree of the least-connected person in the graph\nRemove the least-connected person in the graph and see what happens to the connectivity score\nKeep going until the connectivity score starts to decrease.\n\nWhen you remove one person, you do to things that might affect the overall connectivity score:\n\nYou remove the least-connected person, so in everyone that remains is at least as well connected as that person, and possibly more connected\nYou decrease the degree of everyone that was directly connected to the least-connected person, possibly causing the overall connectivity score to decrease.\n\nDoing that for the counting graph we get\n\n\nCode\nfrom networkx.algorithms.core import core_number\ncore = core_number(G)\nmax_core = max(core.values())\nunweighted_core = [key for key in core.keys() if core[key] == max(core.values())]\nMarkdown(f\"There are {len(unweighted_core)} counters in the unweighted core.\")\n\n\nThere are 118 counters in the unweighted core.\n\n\n\nThe weighted core\nThe approach I’ve just described has an important flaw in that it completely ignores how often two counters have interacted, and only looks at whether they are connected. That means that the connection between two counters who have only one count together is given the same importance as the connection between the counters in Table 1. That seems unfortunate.\nOne way of proceeding would be to apply a threshold and only link two counters in the graph if they have counted together more than X times. That gets rid of the “One count is equivalent to arbitrarily many counts” issue, but isn’t very satisfactory - instead, we get “X - 1 counts is equivalent to 0”, and “X counts is equivalent to arbitrarily many”.\nA better way would be if the strength of the connection could be incorporated into the calculation of the core. I’ll spare you the details, but doing so is a bit tricky. When the network is unweighted, there is a fast algorithm for finding the core (Batagelj and Zaversnik 2003), but adding weights breaks that algorithm. I ended up implementing it myself, you can see the implementation here if you want.\n\nBatagelj, V., and M. Zaversnik. 2003. “An o(m) Algorithm for Cores Decomposition of Networks.” https://arxiv.org/abs/cs/0310049.\nOnce I have a method for taking into account the weighted degree of each node, there are two questions to consider:\n\nHow to model the strength of a single connection\nHow to model the total weight of a node, based on the strength of all the connections it has with other nodes\n\nThe first question is absolutely vital to ask. If the strength of a connection between two counters is defined as just the total number of counts they have together, then no matter what else I do, the core ends up consisting of very few people who all have a lot of counts together.\n\n\nCode\ncoreness = graph_tools.weighted_core_number(G, p=1)\nmax_core_value = max(coreness.values())\nunscaled_core = [x for x in core if coreness[x] == max_core_value]\ns = f\"There are {len(unscaled_core)} counters in the core. They are:\\n\\n - \" + \"\\n- \".join(unscaled_core)\nMarkdown(s)\n\n\nThere are 4 counters in the core. They are:\n\nCountletics\nnonsensy\nthephilsblogbar2\nGarlicoinAccount\n\n\n\nA choice that works fairly well is to model the strength of the connection as the logarithm of the total number of counts. That lets more intense connections have more importance, but within reason.\nThe second question is a bit more subtle, since there’s an intuitive choice that works fairly well, namely just using the sum of all the connection strengths. But that’s not the only way to do things. In the end I ended up taking a weighted combination of the degree of the node and the total connection strength, so that the weighted degree of node \\(i\\), \\(k'_{i}\\) is given by\n\\[\nk'_{i}= \\left(k_{i}\\right)^{1 - p} \\left(\\sum _{\\textrm{neighbors} j}{w_{ij}}\\right)^{p}\n\\]\nwhere the sum runs over all neighbors \\(j\\) of node \\(i\\), \\(w_{ij}\\) is the strength of the connection between \\(i\\) and \\(j\\), and \\(p\\) is a parameter I choose that varies between \\(0\\) and \\(1\\). Setting \\(p = 0\\) means that only the unweighted degree of the node is considered, while setting \\(p = 1\\) means that only the sum of connection strengths matters. In between, you get a mix.\n\n\nCode\ngraph_tools.scale_weights(G)\ncoreness = graph_tools.weighted_core_number(G, p=1)\nmax_core_value = max(coreness.values())\nweighted_core = [x for x in core if coreness[x] == max_core_value]\nnx.set_node_attributes(G, \"periphery\", name=\"k-core\")\nnx.set_node_attributes(G.subgraph(weighted_core), \"core\", name=\"k-core\")\nnx.write_gexf(G, \"../data/graph.gexf\")\ns = f\"There are {len(weighted_core)} counters in the weighted core.\"\nMarkdown(s)\n\n\nThere are 93 counters in the weighted core.\n\n\nThis is a slightly smaller number then counters who were in the core for the unweighted case, and there’s also some difference in the composition of the members that remain:\n\n\nCode\nMarkdown(f\"There are {len(set(weighted_core) ^ set(unweighted_core))} present in only one of the weighted or unweighted core.\")\n\n\nThere are 29 present in only one of the weighted or unweighted core.\n\n\nWith the core in hand, it’s possible to visualise the counting graph again, this time highlighting the members of the weighted core, as shown on Figure 3\n\n\n\nFigure 3: The ~100 core members of the counting graph highlighted in green\n\n\nInterestingly enough the core mainly seems to correspond to the blue team shown on Figure 1, so perhaps my earlier suggestion that the colours mainly correspond to age is incorrect."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analysing rcounting data",
    "section": "",
    "text": "This page highlights some of the initial analysis I’ve done of the counts made on r/counting. To do this, I use the database of all counts that was put together by u/davidjl123 and u/Countletics (and others!), as modified by me. For more niche analysis, see some of the other pages on the sidebar on the left. Most of the figures and tables here have also been posted on the subreddit, but I wanted to have them in a central place. I also liked being able to show the code and the tables or figures it generates in the same document, so that people can see both. Some of it isn’t particularly interesting, so I’ve hidden it behind a code widget. You can unfold it just by clicking.\nThe idea of this page is also that I’ll try and keep the analysis current as more counts come in, while the other pages might slowly grow stale.\n\nImports and initialization\nWe’ll start with some imports, after which we can connect to the database of counts\n\n\nCode for importing packages and connecting to the database\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nimport re\nimport sqlite3\nimport matplotlib.pyplot as plt\n\nfrom rcounting import side_threads, counters, analysis, thread_navigation as tn, parsing\nfrom rcounting.reddit_interface import reddit\nimport seaborn as sns\nsns.set_theme()\nfrom IPython.display import Markdown\ndata_directory = Path(\"../data\")\n\ndb = sqlite3.connect(data_directory / \"counting.sqlite\")\n\n\n\n\nLoading Data\nThen we load some data, both the counts and the gets. We convert the timestamp to a date column, and add a “replying to” column, since some of what we’ll be doing later needs it.\n\n\nCode\ncounts = pd.read_sql(\"select comments.username, comments.submission_id, comments.timestamp \"\n                       \"from comments join submissions \"\n                       \"on comments.submission_id = submissions.submission_id \"\n                       \"where comments.position > 0 \"\n                       \"order by submissions.timestamp, comments.position\", db)\ncounts['date'] = pd.to_datetime(counts['timestamp'], unit='s')\ncounts[\"username\"] = counts[\"username\"].apply(counters.apply_alias)\ncounts.drop('timestamp', inplace=True, axis=1)\ncounts[\"replying_to\"] = counts[\"username\"].shift(1)\nprint(f\"There are {len(counts)} comments logged on main\")\ngets = counts.groupby(\"submission_id\").last().sort_values('date').reset_index()\ngets['basecount'] = (gets.index + 15) * 1000\ngets.loc[[0, 1], ['basecount']] = [0, 16691]\n\n\nThere are 4930935 comments logged on main\n\n\n\n\nCounting progress over time\nA first bit of analysis is to visualize the progress of r/counting over time. That isn’t particularly difficult to do\n\n\nCode\ndata = gets.set_index('date')\nax = (data.resample('30d')[[\"basecount\"]].mean() / 1e6).plot(ylabel='Current count [millions]', xlabel='Date')\nh, l = ax.get_legend_handles_labels()\nax.legend(h[:1],['count'])\nax.set_title('Counting progress over time')\nplt.show()\n\n\n\n\n\nFigure 1: Cumulative counts made on /r/counting as a function of time\n\n\n\n\nOn Figure 1 you can see that the counting rate varies quite a bit over time, with signifcant peaks and lulls in activity. Whether or not there are active runners really changes how fast the count is progressing!\n\n\nTotal counts vs k_parts\nWe can try plotting thread participation vs total counts. The expectation is that generally, people who’ve made more total counts will also have counted in more threads. However, some users might have periods where they make a count every now and then but never do any runs, leading to comparatively more k_parts. On the other hand, some counters might only do runs, giving a counts/thread of up to 500.\nWe’ll start by extracting the number of counts and the threads participated in, using the groupby functionality of pandas\n\n\nCode\n  groups = counts.groupby(\"username\")[\"submission_id\"]\n  k_parts = groups.nunique()\n  hoc = groups.count()\n  combined = pd.concat([k_parts, hoc], axis=1)\n  combined.columns = [\"k_parts\", \"total_counts\"]\n  combined = combined.query(\"k_parts >= 10\")\n\n\nWe can make a polynomial fit of this (well, a linear fit of the log-log quantities), and use matplotlib to plot that\n\n\nCode\nlinear_model = np.polyfit(np.log10(combined.k_parts), np.log10(combined.total_counts), 1)\nprint(linear_model)\naxis = np.linspace(1, combined.k_parts.max(), endpoint=True)\nfig, ax = plt.subplots(1, figsize=(8,5))\nax.scatter(combined.k_parts, combined.total_counts, alpha=0.7)\nax.plot(axis, 10**(np.poly1d(linear_model)(np.log10(axis))), linestyle=\"--\", color=\"0.3\",\n         lw=2)\nax.set_xlabel(\"Threads participated in \")\nax.set_ylabel(\"Total counts made\")\nax.set_yscale(\"log\")\nax.set_xscale(\"log\")\nax.set_xlim(left=10)\nax.set_ylim(bottom=10)\nplt.show()\n\n\n[1.31910452 0.72256103]\n\n\n\n\n\nFigure 2: The relationship between the total number of counts for each user, and then number of threads they’ve participated in\n\n\n\n\nYou can see what that looks like on Figure 2. The dashed line is a linear fit on the log-log plot, and it has a slope of 1.3. In this model, that means that if you double the total number of threads participated in by a user, you would expect to multiply their total counts by 2.5.\n\n\nNumber of partners and effective number of partners\nAs with the number of counts vs threads participated in, we can expect that different counters might have qualitatively different behaviour when it comes to how many counting partners they have, and how often they’ve counted with each one. Some counters might count a little bit with everybody, while others might run with only a few partners, and drop a count with others every now and then.\nTo quantify how uneven the counting distribution is we can look at the effective number of partners of each counter, and compare with the actual number of partners.\n\n\nCode\nsorted_counters = counts.groupby(\"username\").size().sort_values(ascending=False)\ntop_counters = [x for x in sorted_counters.index[:35] if not counters.is_banned_counter(x)][:30]\ntop = sorted_counters.filter(items=top_counters)\ndf = counts.loc[counts[\"username\"].isin(top_counters)].groupby([\"username\", \"replying_to\"]).size()\neffective_partners = df.groupby(level=0).apply(analysis.effective_number_of_counters).to_frame()\npartners = df.groupby(level=0).count()\ncombined = pd.concat([top, effective_partners, partners], axis=1)\ncombined[\"HOC rank\"] = range(1, len(combined) + 1)\ncombined.columns = [\"counts\", \"c_eff\", \"c\", \"rank\"]\ncombined = combined[[\"rank\", \"c\", \"c_eff\"]]\ncombined.c_eff = combined.c_eff.round().astype(int)\ncombined.columns = [\"HOC rank\", \"N\", \"N_(effective)\"]\ncombined.index.name = \"Username\"\ncombined.head(25)\n\n\n\n\n\n\n  \n    \n      \n      HOC rank\n      N\n      N_(effective)\n    \n    \n      Username\n      \n      \n      \n    \n  \n  \n    \n      thephilsblogbar2\n      1\n      1372\n      12\n    \n    \n      Countletics\n      2\n      509\n      8\n    \n    \n      davidjl123\n      3\n      1578\n      23\n    \n    \n      Antichess\n      4\n      756\n      9\n    \n    \n      GarlicoinAccount\n      5\n      388\n      4\n    \n    \n      Smartstocks\n      6\n      1054\n      29\n    \n    \n      nonsensy\n      7\n      261\n      3\n    \n    \n      TheNitromeFan\n      8\n      1879\n      33\n    \n    \n      atomicimploder\n      9\n      2442\n      31\n    \n    \n      qwertylool\n      10\n      371\n      7\n    \n    \n      Ezekiel134\n      11\n      894\n      13\n    \n    \n      Trial-Name\n      12\n      154\n      4\n    \n    \n      rideride\n      13\n      684\n      11\n    \n    \n      RandomRedditorWithNo\n      14\n      744\n      22\n    \n    \n      Urbul\n      15\n      1084\n      30\n    \n    \n      Mooraell\n      16\n      1193\n      24\n    \n    \n      qualw\n      17\n      267\n      10\n    \n    \n      kdiuro13\n      18\n      841\n      24\n    \n    \n      ClockButTakeOutTheL\n      19\n      144\n      2\n    \n    \n      Removedpixel\n      20\n      1198\n      25\n    \n    \n      Adinida\n      21\n      299\n      9\n    \n    \n      TehVulpez\n      22\n      674\n      19\n    \n    \n      rschaosid\n      23\n      335\n      18\n    \n    \n      LeMinerWithCheese\n      24\n      89\n      7\n    \n    \n      timo78888\n      25\n      320\n      15\n    \n  \n\n\n\n\nWe can also get the replying-to and replied-by stats for a single user\n\n\nCode\ncounter = \"thephilsblogbar2\"\nnick = \"phil\"\nsubset = counts.loc[counts[\"username\"] == counter].copy()\nreplied_by = counts['username'].shift(-1).loc[subset.index]\nsubset['replied_by'] = replied_by\nresult = pd.concat([subset.groupby(\"replied_by\").count().iloc[:, 0].sort_values(ascending=False),\n                    subset.groupby(\"replying_to\").count().iloc[:, 0].sort_values(ascending=False)], axis=1).head(10)\nMarkdown(result.to_markdown(headers=['Counting partner', f'No. of replies by {nick}', f'No. of replies to {nick}']))\n\n\n\n\nTable 1: The most popular counting partners of a single user\n\n\n\n\n\n\n\nCounting partner\nNo. of replies by phil\nNo. of replies to phil\n\n\n\n\nGarlicoinAccount\n98821\n98844\n\n\nClockButTakeOutTheL\n39801\n39788\n\n\nCountletics\n34463\n34534\n\n\nTheNitromeFan\n16095\n16193\n\n\nAntichess\n15220\n15353\n\n\nTrial-Name\n11529\n11560\n\n\namazingpikachu_38\n11492\n11484\n\n\nCutOnBumInBandHere9\n11322\n11428\n\n\natomicimploder\n10794\n10867\n\n\nnonsensy\n10535\n10513\n\n\n\n\n\n\n\n\nOldest counters\nWe can see who the oldest still-active counters are, where still-active is generously defined as “having made a count within the last six months”.\n\n\nCode\ncutoff_date = pd.to_datetime('today') - pd.Timedelta('180d')\nactive_counters = counts.loc[counts['date'] > cutoff_date].groupby(\"username\").groups.keys()\noldest_counters = counts.loc[counts['username'].isin(active_counters)].groupby(\"username\")[\"date\"].agg([min, max])\noldest_counters = oldest_counters.sort_values('min').head(25)\nMarkdown(oldest_counters.apply(lambda x: x.dt.date).to_markdown(headers=[\"**username**\", \"**First Count**\", \"**Latest Count**\"]))\n\n\n\n\nTable 2: The 25 currently-active counters who’ve been counting for the longest time\n\n\nusername\nFirst Count\nLatest Count\n\n\n\n\nZ3F\n2012-06-10\n2022-12-25\n\n\nCanGreenBeret\n2012-06-12\n2022-12-06\n\n\n949paintball\n2012-06-15\n2022-12-27\n\n\nPookah\n2012-09-06\n2022-11-25\n\n\nkdiuro13\n2013-04-07\n2022-10-28\n\n\nzhige\n2013-05-03\n2022-12-25\n\n\nfalsehood\n2013-06-24\n2022-12-24\n\n\nAschebescher\n2013-06-24\n2022-11-08\n\n\nsudofox\n2013-12-13\n2022-09-16\n\n\nCutOnBumInBandHere9\n2013-12-13\n2023-01-20\n\n\noohbopbadoo\n2013-12-13\n2022-10-11\n\n\nKingCaspianX\n2014-01-18\n2022-09-28\n\n\nOreoObserver\n2014-01-25\n2023-01-04\n\n\nyeontura\n2014-02-26\n2022-10-25\n\n\natomicimploder\n2014-02-26\n2023-01-20\n\n\norigamimissile\n2014-03-10\n2022-10-27\n\n\nSThor\n2014-03-10\n2022-08-04\n\n\nrideride\n2014-04-07\n2022-10-05\n\n\nJuqu\n2014-04-12\n2023-01-17\n\n\nGregsquatch\n2014-04-27\n2022-09-24\n\n\nrschaosid\n2014-04-27\n2022-09-28\n\n\nbittrashed\n2014-05-02\n2022-10-07\n\n\nNoBreadsticks\n2014-05-15\n2022-08-13\n\n\nBlimp_Blimp\n2014-06-29\n2022-12-13\n\n\nartbn\n2014-07-06\n2023-01-15\n\n\n\n\n\n\n\n\nGets and streaks\nSimilarly to the oldest counters, we can see what the longest difference between a counter’s first and last get is, and that’s shown on Table 3. Some counters have been active and getting gets for quite a while!\n\n\nCode\n  Markdown(gets.groupby('username').agg(lambda x: x.index[-1] - x.index[0]).iloc[:, 0].sort_values(ascending=False).head(10).to_markdown(headers=[\"**Username**\", \"**Get span**\"]))\n\n\n\n\nTable 3: The longest differences between the first and last get of r/counting users (1000s of counts)\n\n\nUsername\nGet span\n\n\n\n\natomicimploder\n4740\n\n\norigamimissile\n4577\n\n\nManiac_34\n4575\n\n\nMooraell\n4563\n\n\nmusicbuilder\n4515\n\n\nPookah\n4500\n\n\nFartyMcNarty\n4373\n\n\nTheNitromeFan\n4305\n\n\ndavidjl123\n4111\n\n\nSmartstocks\n4083\n\n\n\n\n\n\nWe can also calculate what the longest get streaks are.\n\n\nCode\ny = gets['username']\ngroups = gets.groupby((y != y.shift()).cumsum())\ncolumns = ['username', 'submission_id', 'basecount']\nlength = 10\n\nindices = (-groups.size()).sort_values(kind='mergesort').index\nold = groups.first().loc[indices, columns]\nnew = groups.last().loc[indices, columns]\ncombined = old.join(new, rsuffix='_new')\ncombined = combined.loc[~combined['username'].apply(counters.is_banned_counter)].head(length).reset_index(drop=True)\ncombined['old_link'] = combined.apply(lambda x: f'[{int(x.basecount / 1000) + 1}K](https://reddit.com/comments/{x.submission_id}/)', axis=1)\ncombined['new_link'] = combined.apply(lambda x: f'[{int(x.basecount_new / 1000) + 1}K](https://reddit.com/comments/{x.submission_id_new}/)', axis=1)\ncombined['streak'] = 1 + (combined['basecount_new'] - combined['basecount']) // 1000\ncombined.index += 1\ncombined.index.name = \"Rank\"\nMarkdown(combined[['username', 'old_link', 'new_link', 'streak']].to_markdown(headers=['**Rank**', '**username**', '**First Get**', '**Last Get**', '**Streak Length**']))\n\n\n\n\nTable 4: The longest streak\n\n\nRank\nusername\nFirst Get\nLast Get\nStreak Length\n\n\n\n\n1\nCountletics\n2896K\n2914K\n19\n\n\n2\nLeMinerWithCheese\n4570K\n4584K\n15\n\n\n3\ndavidjl123\n3038K\n3047K\n10\n\n\n4\nCountletics\n3091K\n3100K\n10\n\n\n5\nCountletics\n3190K\n3199K\n10\n\n\n6\nCountletics\n4384K\n4393K\n10\n\n\n7\nqualw\n2042K\n2049K\n8\n\n\n8\ndavidjl123\n3726K\n3733K\n8\n\n\n9\nqwertylool\n4440K\n4447K\n8\n\n\n10\ncountmeister\n290K\n296K\n7\n\n\n\n\n\n\nThe core of the extraction is the line that says groups = gets.groupby((y != y.shift()).cumsum()). Let’s unpack it:\n\ny != y.shift() assigns a value of True to all threads with a username that’s different from their predecessor\n.cumsum() sums up all these True values. The net result is that each get streak is given its own unique number\n.groupby() extracts these groups for later use\n\nThe groups are then sorted according to size, and the largest ones are shown in Table 4"
  }
]